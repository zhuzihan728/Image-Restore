{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhuzihan728/Image-Restore/blob/main/restormer_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeGEHo0VjpY5"
      },
      "source": [
        "# Restormer: Efficient Transformer for High-Resolution Image Restoration (CVPR 2022 -- Oral) [![paper](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2111.09881)\n",
        "\n",
        "<hr />\n",
        "\n",
        "This is a demo to run Restormer on you own images for the following tasks\n",
        "- Real Image Denoising\n",
        "- Single-Image Defocus Deblurring\n",
        "- Single-Image Motion Deblurring\n",
        "- Image Deraining\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRd46QaXlklQ"
      },
      "source": [
        "# 1. Setup\n",
        "- First, in the **Runtime** menu -> **Change runtime type**, make sure to have ```Hardware Accelerator = GPU```\n",
        "- Clone repo and install dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GLDZ9t1pm9JZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fd4d5e0-675c-4a75-ecd4-8acc0fbd9a56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Cloning into 'Restormer'...\n",
            "remote: Enumerating objects: 312, done.\u001b[K\n",
            "remote: Counting objects: 100% (115/115), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 312 (delta 74), reused 72 (delta 72), pack-reused 197 (from 2)\u001b[K\n",
            "Receiving objects: 100% (312/312), 1.55 MiB | 5.11 MiB/s, done.\n",
            "Resolving deltas: 100% (131/131), done.\n",
            "/content/Restormer\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "!pip install einops\n",
        "\n",
        "if os.path.isdir('Restormer'):\n",
        "  !rm -r Restormer\n",
        "\n",
        "# Clone Restormer\n",
        "!git clone https://github.com/swz30/Restormer.git\n",
        "%cd Restormer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXxtBPA1tGxL"
      },
      "source": [
        "# 2. Define Task and Download Pre-trained Models\n",
        "Uncomment the task you would like to perform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZM4ksCkZtqUA",
        "outputId": "3dfcd7c6-3d1e-4065-c146-3f3ded8b41a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-07 15:27:02--  https://github.com/swz30/Restormer/releases/download/v1.0/real_denoising.pth\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/418793252/577ea2a7-8cf3-44b2-900d-5368f402de29?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-07T16%3A04%3A04Z&rscd=attachment%3B+filename%3Dreal_denoising.pth&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-07T15%3A03%3A38Z&ske=2025-12-07T16%3A04%3A04Z&sks=b&skv=2018-11-09&sig=Ltxy6%2Ft2J5MMzfb6QXeoSpag5XVYGyhZfXX%2BLWGE1Ss%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NTEyMzAyMiwibmJmIjoxNzY1MTIxMjIyLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.Uk5JEp6YIihYicVFYvpxeRblFuuyTdvJDBrbHo47eoU&response-content-disposition=attachment%3B%20filename%3Dreal_denoising.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-12-07 15:27:02--  https://release-assets.githubusercontent.com/github-production-release-asset/418793252/577ea2a7-8cf3-44b2-900d-5368f402de29?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-07T16%3A04%3A04Z&rscd=attachment%3B+filename%3Dreal_denoising.pth&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-07T15%3A03%3A38Z&ske=2025-12-07T16%3A04%3A04Z&sks=b&skv=2018-11-09&sig=Ltxy6%2Ft2J5MMzfb6QXeoSpag5XVYGyhZfXX%2BLWGE1Ss%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NTEyMzAyMiwibmJmIjoxNzY1MTIxMjIyLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.Uk5JEp6YIihYicVFYvpxeRblFuuyTdvJDBrbHo47eoU&response-content-disposition=attachment%3B%20filename%3Dreal_denoising.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 104611957 (100M) [application/octet-stream]\n",
            "Saving to: ‘Denoising/pretrained_models/real_denoising.pth’\n",
            "\n",
            "real_denoising.pth  100%[===================>]  99.77M  50.0MB/s    in 2.0s    \n",
            "\n",
            "2025-12-07 15:27:04 (50.0 MB/s) - ‘Denoising/pretrained_models/real_denoising.pth’ saved [104611957/104611957]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "task = 'Real_Denoising'\n",
        "# task = 'Single_Image_Defocus_Deblurring'\n",
        "# task = 'Motion_Deblurring'\n",
        "# task = 'Deraining'\n",
        "\n",
        "# Download the pre-trained models\n",
        "if task == 'Real_Denoising' and not len(os.listdir('Denoising/pretrained_models')) >= 2:\n",
        "  !wget https://github.com/swz30/Restormer/releases/download/v1.0/real_denoising.pth -P Denoising/pretrained_models\n",
        "if task == 'Single_Image_Defocus_Deblurring' and not len(os.listdir('Defocus_Deblurring/pretrained_models')) >= 2:\n",
        "  !wget https://github.com/swz30/Restormer/releases/download/v1.0/single_image_defocus_deblurring.pth -P Defocus_Deblurring/pretrained_models\n",
        "if task == 'Motion_Deblurring' and not len(os.listdir('Motion_Deblurring/pretrained_models')) >= 2:\n",
        "  !wget https://github.com/swz30/Restormer/releases/download/v1.0/motion_deblurring.pth -P Motion_Deblurring/pretrained_models\n",
        "if task == 'Deraining' and not len(os.listdir('Deraining/pretrained_models')) >= 2:\n",
        "  !wget https://github.com/swz30/Restormer/releases/download/v1.0/deraining.pth -P Deraining/pretrained_models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9nwA_Prt7PI"
      },
      "source": [
        "# 3. Upload Images\n",
        "Either download the sample images or upload your own images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7ArqQfvBbRf"
      },
      "source": [
        "# 4. Prepare Model and Load Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sOJN6gHGCKGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fa4315b-247d-4319-e69b-7efca7633abb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  patch_embed.proj.weight:\n",
            "    Before: mean=0.001388\n",
            "    After:  mean=-0.001572\n",
            "  encoder_level1.0.norm1.body.weight:\n",
            "    Before: mean=1.000000\n",
            "    After:  mean=0.770190\n",
            "  encoder_level1.0.attn.temperature:\n",
            "    Before: mean=1.000000\n",
            "    After:  mean=0.632537\n",
            "Loaded model from Denoising/pretrained_models/real_denoising.pth.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "from runpy import run_path\n",
        "from skimage import img_as_ubyte\n",
        "from natsort import natsorted\n",
        "from glob import glob\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "def get_weights_and_parameters(task, parameters):\n",
        "    if task == 'Motion_Deblurring':\n",
        "        weights = os.path.join('Motion_Deblurring', 'pretrained_models', 'motion_deblurring.pth')\n",
        "    elif task == 'Single_Image_Defocus_Deblurring':\n",
        "        weights = os.path.join('Defocus_Deblurring', 'pretrained_models', 'single_image_defocus_deblurring.pth')\n",
        "    elif task == 'Deraining':\n",
        "        weights = os.path.join('Deraining', 'pretrained_models', 'deraining.pth')\n",
        "    elif task == 'Real_Denoising':\n",
        "        weights = os.path.join('Denoising', 'pretrained_models', 'real_denoising.pth')\n",
        "        parameters['LayerNorm_type'] =  'BiasFree'\n",
        "    return weights, parameters\n",
        "\n",
        "\n",
        "# Get model weights and parameters\n",
        "parameters = {'inp_channels':3, 'out_channels':3, 'dim':48, 'num_blocks':[4,6,6,8], 'num_refinement_blocks':4, 'heads':[1,2,4,8], 'ffn_expansion_factor':2.66, 'bias':False, 'LayerNorm_type':'WithBias', 'dual_pixel_task':False}\n",
        "weights, parameters = get_weights_and_parameters(task, parameters)\n",
        "\n",
        "load_arch = run_path(os.path.join('basicsr', 'models', 'archs', 'restormer_arch.py'))\n",
        "model = load_arch['Restormer'](**parameters)\n",
        "model.cuda()\n",
        "# # check model loading\n",
        "# initial_params = {name: param.clone() for name, param in model.named_parameters()}\n",
        "\n",
        "\n",
        "checkpoint = torch.load(weights)\n",
        "model.load_state_dict(checkpoint['params'])\n",
        "\n",
        "model.eval()\n",
        "# # check model loading\n",
        "# for i, (name, param) in enumerate(model.named_parameters()):\n",
        "#     if i < 3:\n",
        "#         initial_mean = initial_params[name].mean().item()\n",
        "#         loaded_mean = param.mean().item()\n",
        "#         print(f\"  {name}:\")\n",
        "#         print(f\"    Before: mean={initial_mean:.6f}\")\n",
        "#         print(f\"    After:  mean={loaded_mean:.6f}\")\n",
        "\n",
        "print(f\"Loaded model from {weights}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDvxkztWDsYd"
      },
      "source": [
        "# 5. Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odPtmz_lD2Rd"
      },
      "outputs": [],
      "source": [
        "# input_dir = 'demo/sample_images/'+task+'/degraded'\n",
        "# out_dir = 'demo/sample_images/'+task+'/restored'\n",
        "# os.makedirs(out_dir, exist_ok=True)\n",
        "# extensions = ['jpg', 'JPG', 'png', 'PNG', 'jpeg', 'JPEG', 'bmp', 'BMP']\n",
        "# files = natsorted(glob(os.path.join(input_dir, '*')))\n",
        "\n",
        "# img_multiple_of = 8\n",
        "\n",
        "# print(f\"\\n ==> Running {task} with weights {weights}\\n \")\n",
        "# with torch.no_grad():\n",
        "#   for filepath in tqdm(files):\n",
        "#       # print(file_)\n",
        "#       torch.cuda.ipc_collect()\n",
        "#       torch.cuda.empty_cache()\n",
        "#       img = cv2.cvtColor(cv2.imread(filepath), cv2.COLOR_BGR2RGB)\n",
        "#       input_ = torch.from_numpy(img).float().div(255.).permute(2,0,1).unsqueeze(0).cuda()\n",
        "\n",
        "#       # Pad the input if not_multiple_of 8\n",
        "#       h,w = input_.shape[2], input_.shape[3]\n",
        "#       H,W = ((h+img_multiple_of)//img_multiple_of)*img_multiple_of, ((w+img_multiple_of)//img_multiple_of)*img_multiple_of\n",
        "#       padh = H-h if h%img_multiple_of!=0 else 0\n",
        "#       padw = W-w if w%img_multiple_of!=0 else 0\n",
        "#       input_ = F.pad(input_, (0,padw,0,padh), 'reflect')\n",
        "\n",
        "#       restored = model(input_)\n",
        "#       restored = torch.clamp(restored, 0, 1)\n",
        "\n",
        "#       # Unpad the output\n",
        "#       restored = restored[:,:,:h,:w]\n",
        "\n",
        "#       restored = restored.permute(0, 2, 3, 1).cpu().detach().numpy()\n",
        "#       restored = img_as_ubyte(restored[0])\n",
        "\n",
        "#       filename = os.path.split(filepath)[-1]\n",
        "#       cv2.imwrite(os.path.join(out_dir, filename),cv2.cvtColor(restored, cv2.COLOR_RGB2BGR))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVesdzl9JCZy",
        "outputId": "9493f8d6-3adb-4a4f-e27a-e7a4b619122c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
        "from skimage import img_as_ubyte\n",
        "import cv2\n",
        "import json\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "class EvalDataset:\n",
        "    def __init__(self, corrupted_dir, original_dir, mask_dir, metadata_path,\n",
        "                 im_size=None, transform=None):\n",
        "        \"\"\"\n",
        "        :param corrupted_dir: path to corrupted images folder\n",
        "        :param original_dir: path to original images folder\n",
        "        :param mask_dir: path to mask images folder\n",
        "        :param metadata_path: path to metadata.json\n",
        "        :param im_size: target size (h, w) or None to keep original\n",
        "        \"\"\"\n",
        "        self.corrupted_dir = corrupted_dir\n",
        "        self.original_dir = original_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.im_size = im_size\n",
        "        self.transform = transform\n",
        "\n",
        "        with open(metadata_path, 'r') as f:\n",
        "            self.metadata = json.load(f)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.metadata)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        meta = self.metadata[idx]\n",
        "\n",
        "        # Load images using names from metadata\n",
        "        corrupted = Image.open(os.path.join(self.corrupted_dir, meta['corrupted_image']))\n",
        "        original = Image.open(os.path.join(self.original_dir, meta['original_image']))\n",
        "\n",
        "        # Resize if needed\n",
        "        if self.im_size:\n",
        "            corrupted = corrupted.resize(self.im_size, Image.Resampling.LANCZOS)\n",
        "            original = original.resize(self.im_size, Image.Resampling.LANCZOS)\n",
        "\n",
        "        if self.transform:\n",
        "            corrupted = self.transform(corrupted)\n",
        "            original = self.transform(original)\n",
        "\n",
        "        return corrupted, original, meta\n",
        "\n",
        "# Usage in evaluation:\n",
        "# eval_dataset = EvalDataset(\n",
        "#     corrupted_dir='eval_dataset/corrupted/',\n",
        "#     original_dir='images/',  # Original folder\n",
        "#     mask_dir='backgrounds/',  # Mask folder\n",
        "#     metadata_path='eval_dataset/metadata.json',\n",
        "#     im_size=(256, 256)\n",
        "# )\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
        "from skimage import img_as_ubyte\n",
        "import cv2\n",
        "import json\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "class ImageRecoveryEvaluator:\n",
        "    def __init__(self, model, eval_dataset, output_dir, task):\n",
        "        self.model = model\n",
        "        self.dataset = eval_dataset\n",
        "        self.output_dir = f\"{output_dir}_{task}\"\n",
        "        os.makedirs(os.path.join(self.output_dir, 'restored'), exist_ok=True)\n",
        "\n",
        "    def rgb_to_y(self, img):\n",
        "        \"\"\"Convert RGB to Y channel - matches MATLAB rgb2ycbcr\"\"\"\n",
        "        from skimage.color import rgb2ycbcr\n",
        "        img_ycbcr = rgb2ycbcr(img)  # Expects float [0,1] or uint8 [0,255]\n",
        "        return img_ycbcr[:, :, 0]\n",
        "\n",
        "    def evaluate(self):\n",
        "        results = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for idx in tqdm(range(len(self.dataset))):\n",
        "                torch.cuda.ipc_collect()\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "                # Load images\n",
        "                corrupted, original, meta = self.dataset[idx]\n",
        "\n",
        "                # Convert PIL to numpy if needed\n",
        "                if hasattr(corrupted, 'convert'):\n",
        "                    corrupted_np = np.array(corrupted.convert('RGB'))\n",
        "                    original_np = np.array(original.convert('RGB'))\n",
        "                else:\n",
        "                    corrupted_np = corrupted\n",
        "                    original_np = original\n",
        "\n",
        "                # Prepare input\n",
        "                input_ = torch.from_numpy(corrupted_np).float().div(255.).permute(2,0,1).unsqueeze(0).cuda()\n",
        "\n",
        "                # # Pad to multiple of 8\n",
        "                # img_multiple_of = 8\n",
        "                # h, w = input_.shape[2], input_.shape[3]\n",
        "                # H = ((h + self.img_multiple_of) // self.img_multiple_of) * self.img_multiple_of\n",
        "                # W = ((w + self.img_multiple_of) // self.img_multiple_of) * self.img_multiple_of\n",
        "                # padh = H - h if h % self.img_multiple_of != 0 else 0\n",
        "                # padw = W - w if w % self.img_multiple_of != 0 else 0\n",
        "                # input_ = F.pad(input_, (0, padw, 0, padh), 'reflect')\n",
        "\n",
        "                # Restore\n",
        "                restored = self.model(input_)\n",
        "                restored = torch.clamp(restored, 0, 1)\n",
        "\n",
        "                # Unpad\n",
        "                # restored = restored[:, :, :h, :w]\n",
        "\n",
        "                # Convert to numpy\n",
        "                restored_np = restored.permute(0, 2, 3, 1).cpu().detach().numpy()\n",
        "                restored_np = img_as_ubyte(restored_np[0])\n",
        "\n",
        "                # Calculate RGB metrics\n",
        "                psnr_rgb = peak_signal_noise_ratio(original_np, restored_np, data_range=255)\n",
        "                ssim_rgb = structural_similarity(original_np, restored_np, channel_axis=2, data_range=255)\n",
        "                mae = np.mean(np.abs(original_np.astype(float) - restored_np.astype(float)))\n",
        "                mse = np.mean((original_np.astype(float) - restored_np.astype(float)) ** 2)\n",
        "\n",
        "                # Calculate Y channel metrics\n",
        "                original_y = self.rgb_to_y(original_np)\n",
        "                restored_y = self.rgb_to_y(restored_np)\n",
        "                psnr_y = peak_signal_noise_ratio(original_y, restored_y, data_range=255)\n",
        "                ssim_y = structural_similarity(original_y, restored_y, data_range=255)\n",
        "\n",
        "                # Save restored image\n",
        "                filename = meta['corrupted_image'].replace('_alpha', '_restored_alpha')\n",
        "                cv2.imwrite(\n",
        "                    os.path.join(self.output_dir, 'restored', filename),\n",
        "                    cv2.cvtColor(restored_np, cv2.COLOR_RGB2BGR)\n",
        "                )\n",
        "\n",
        "                # Store results\n",
        "                result = {\n",
        "                    **meta,\n",
        "                    'psnr_rgb': float(psnr_rgb),\n",
        "                    'ssim_rgb': float(ssim_rgb),\n",
        "                    'psnr_y': float(psnr_y),\n",
        "                    'ssim_y': float(ssim_y),\n",
        "                    'mae': float(mae),\n",
        "                    'mse': float(mse),\n",
        "                    'restored_image': filename\n",
        "                }\n",
        "                results.append(result)\n",
        "\n",
        "        # Save metrics\n",
        "        with open(os.path.join(self.output_dir, 'eval_results.json'), 'w') as f:\n",
        "            json.dump(results, f, indent=2)\n",
        "\n",
        "        # Print summary\n",
        "        print(f\"\\n=== Evaluation Results ===\")\n",
        "        print(f\"Average PSNR (RGB): {np.mean([r['psnr_rgb'] for r in results]):.2f} dB\")\n",
        "        print(f\"Average SSIM (RGB): {np.mean([r['ssim_rgb'] for r in results]):.4f}\")\n",
        "        print(f\"Average PSNR (Y):   {np.mean([r['psnr_y'] for r in results]):.2f} dB\")\n",
        "        print(f\"Average SSIM (Y):   {np.mean([r['ssim_y'] for r in results]):.4f}\")\n",
        "        print(f\"Average MAE:        {np.mean([r['mae'] for r in results]):.2f}\")\n",
        "        print(f\"Average MSE:        {np.mean([r['mse'] for r in results]):.2f}\")\n",
        "\n",
        "        avg_metrics = []\n",
        "        alpha_ranges = list(set(str(r['alpha_range']) for r in results))\n",
        "        alpha_ranges.sort()\n",
        "\n",
        "        for alpha_range in alpha_ranges:\n",
        "            alpha_results = [r for r in results if str(r['alpha_range']) == alpha_range]\n",
        "            avg_metrics_alpha = {\n",
        "                'alpha_range': alpha_range,\n",
        "                'count': len(alpha_results),\n",
        "                'avg_psnr': float(np.mean([r['psnr'] for r in alpha_results])),\n",
        "                'avg_ssim': float(np.mean([r['ssim'] for r in alpha_results])),\n",
        "                'avg_mae': float(np.mean([r['mae'] for r in alpha_results])),\n",
        "                'avg_mse': float(np.mean([r['mse'] for r in alpha_results]))\n",
        "            }\n",
        "            avg_metrics.append(avg_metrics_alpha)\n",
        "            print(f\"Alpha {alpha_range}: PSNR={avg_metrics_alpha['avg_psnr']:.2f}, SSIM={avg_metrics_alpha['avg_ssim']:.4f}\")\n",
        "\n",
        "        avg_metrics_total = {\n",
        "            'alpha_range': 'total',\n",
        "            'count': len(results),\n",
        "            'avg_psnr': float(np.mean([r['psnr'] for r in results])),\n",
        "            'avg_ssim': float(np.mean([r['ssim'] for r in results])),\n",
        "            'avg_mae': float(np.mean([r['mae'] for r in results])),\n",
        "            'avg_mse': float(np.mean([r['mse'] for r in results]))\n",
        "        }\n",
        "        avg_metrics.append(avg_metrics_total)\n",
        "\n",
        "        with open(os.path.join(self.output_dir, 'avg_metrics.json'), 'w') as f:\n",
        "            json.dump(avg_metrics, f, indent=2)\n",
        "        return results\n",
        "\n",
        "# Usage\n",
        "eval_dataset = EvalDataset(\n",
        "    corrupted_dir='/content/drive/MyDrive/eval_dataset/corrupted/',\n",
        "    original_dir='/content/drive/MyDrive/image_test/',\n",
        "    mask_dir='/content/drive/MyDrive/mask/',\n",
        "    metadata_path='/content/drive/MyDrive/eval_dataset/metadata.json'\n",
        ")\n",
        "\n",
        "# # Test on a single image first\n",
        "# corrupted, original, meta = eval_dataset[2]\n",
        "# corrupted_np = np.array(corrupted.convert('RGB'))\n",
        "\n",
        "# # Check input\n",
        "# print(f\"Input shape: {corrupted_np.shape}\")\n",
        "# print(f\"Input range: [{corrupted_np.min()}, {corrupted_np.max()}]\")\n",
        "\n",
        "# # Run model\n",
        "# input_ = torch.from_numpy(corrupted_np).float().div(255.).permute(2,0,1).unsqueeze(0).cuda()\n",
        "# print(f\"Model input shape: {input_.shape}\")\n",
        "# print(f\"Model input range: [{input_.min()}, {input_.max()}]\")\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     restored = model(input_)\n",
        "# restored = torch.clamp(restored, 0, 1)\n",
        "\n",
        "# print(f\"Model output shape: {restored.shape}\")\n",
        "# print(f\"Model output range: [{restored.min()}, {restored.max()}]\")\n",
        "\n",
        "# # Visualize\n",
        "# import matplotlib.pyplot as plt\n",
        "# fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "# axes[0].imshow(corrupted_np)\n",
        "# axes[0].set_title('Corrupted Input')\n",
        "# axes[1].imshow(restored.permute(0,2,3,1).cpu().numpy()[0])\n",
        "# axes[1].set_title('Model Output')\n",
        "# axes[2].imshow(np.array(original.convert('RGB')))\n",
        "# axes[2].set_title('Original')\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "CNTjn1T6FJVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYG9bFUSvEb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4888071-7c2b-4eb4-cbc7-4a39b1e63023"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 264/300 [15:59<02:14,  3.75s/it]"
          ]
        }
      ],
      "source": [
        "evaluator = ImageRecoveryEvaluator(\n",
        "    model=model,\n",
        "    eval_dataset=eval_dataset,\n",
        "    output_dir='/content/drive/MyDrive/eval_results',\n",
        "    task = task\n",
        ")\n",
        "\n",
        "results = evaluator.evaluate()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}